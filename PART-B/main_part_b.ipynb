{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U83iQvy_aVB6"
      },
      "outputs": [],
      "source": [
        "#Reference https://rumn.medium.com/part-1-ultimate-guide-to-fine-tuning-in-pytorch-pre-trained-model-and-its-configuration-8990194b71e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rNXPcfdaUqs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Gf7ft4yMQtj"
      },
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI61QxVPmnAO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7vqOzAIPQIc",
        "outputId": "db539932-534b-44de-b000-1c55429fab7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/CS6910-A2/CS6910-A2/train'\n",
        "test_dir = '/content/drive/MyDrive/CS6910-A2/CS6910-A2/val'\n",
        "\n",
        "#train_dir = '/kaggle/input/inaturalist/inaturalist_12K/train'\n",
        "#test_dir = '/kaggle/input/inaturalist/inaturalist_12K/val'\n",
        "IMG_SIZE = (224,224)\n",
        "\n",
        "# Transformations to apply to the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),  # Resize the images\n",
        "    transforms.ToTensor(),        # Convert images to PyTorch tensors\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ])  # Normalize the images\n",
        "\n",
        "\n",
        "# Use ImageFolder to create a dataset\n",
        "trainset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "val_size = int(0.2 * len(trainset))\n",
        "train_size = len(trainset) - val_size\n",
        "trainset, valset = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzJfMRBCcB45"
      },
      "outputs": [],
      "source": [
        "class pretrainedCNN():\n",
        "  def __init__(self, trainset, valset, model, batch_size=32, freeze_percent = 1):\n",
        "    # freeze earlier layers\n",
        "    self.model = model\n",
        "    if freeze_percent==1:\n",
        "      for param in self.model.parameters():\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "      total_layers = sum(1 for _ in model.parameters())\n",
        "      num_layers_to_freeze = int(freeze_percent * total_layers)\n",
        "\n",
        "      # Counter to track the number of frozen layers\n",
        "      frozen_layers = 0\n",
        "\n",
        "      # Freeze layers until reaching the desired percentage\n",
        "      for param in self.model.parameters():\n",
        "          param.requires_grad = False\n",
        "          frozen_layers += 1\n",
        "          if frozen_layers >= num_layers_to_freeze:\n",
        "              break\n",
        "\n",
        "    # Modify fully connected layer for fine-tuning\n",
        "    num_classes = 10  # Number of classes in iNaturalist dataset\n",
        "    num_ftrs = self.model.fc.in_features\n",
        "    model.fc = torch.nn.Linear(num_ftrs, num_classes)\n",
        "    for param in self.model.fc.parameters():\n",
        "      param.requires_grad = True\n",
        "    # DataLoader for the dataset\n",
        "    self.dataloader_train = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle=True)\n",
        "    self.dataloader_val = torch.utils.data.DataLoader(valset, batch_size = batch_size, shuffle=True)\n",
        "\n",
        "  def train(self, epochs = 10, lr=0.001, weight_decay=0):\n",
        "    self.model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    for epoch in range(1,epochs+1):\n",
        "      train_accuracy = 0\n",
        "      count = 0\n",
        "      self.model.train()\n",
        "      for inputs, labels in self.dataloader_train:\n",
        "          # forward, backward, and then weight update\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "          # Forward pass\n",
        "          optimizer.zero_grad()\n",
        "          y_pred = self.model(inputs)\n",
        "          loss = criterion(y_pred, labels)\n",
        "          train_accuracy += (torch.argmax(y_pred, 1) == labels).float().sum()\n",
        "          count += len(labels)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      train_accuracy /= count\n",
        "      print(\"Epoch %d: model train accuracy %.2f%%\" % (epoch, train_accuracy*100))\n",
        "      wandb.log({ 'epoch': epoch, 'train_accuracy': train_accuracy * 100})\n",
        "      self.model.eval()\n",
        "      with torch.no_grad():\n",
        "        val_accuracy = 0\n",
        "        count = 0\n",
        "        for inputs, labels in self.dataloader_val:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            y_pred = self.model(inputs)\n",
        "            val_loss = criterion(y_pred, labels)\n",
        "            val_accuracy += (torch.argmax(y_pred, 1) == labels).float().sum()\n",
        "            count += len(labels)\n",
        "        val_accuracy /= count\n",
        "        print(\"Epoch %d: model validation accuracy %.2f%%\" % (epoch, val_accuracy*100))\n",
        "        wandb.log({ 'epoch': epoch, 'validation_accuracy': val_accuracy * 100})\n",
        "        wandb.log({ 'epoch': epoch, 'validation_loss': val_loss * 100})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vwGMonkKo9q"
      },
      "outputs": [],
      "source": [
        "# sweep config file\n",
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'name' : 'sweep - pretuning',\n",
        "    'metric': {\n",
        "      'goal': 'maximize',\n",
        "      'name': 'validation_accuracy'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'lr': {\n",
        "            'values': [1e-3, 1e-4]\n",
        "        },\n",
        "        'freeze_percent':{\n",
        "            'values': [0.2, 0.6, 0.9]\n",
        "        },\n",
        "        'l2_reg':{\n",
        "            'values': [0, 0.0005, 0.05]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [32, 64]\n",
        "        },\n",
        "        'epochs':{\n",
        "            'values': [5, 10]   #, 10]\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "1E7h8eZLNnkA",
        "outputId": "776157e6-e1f2-413d-a26e-8b377b8439f9"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 632bicm4\n",
            "Sweep URL: https://wandb.ai/abhinavtk/MA23M002-A2/sweeps/632bicm4\n"
          ]
        }
      ],
      "source": [
        "# Create a sweep\n",
        "sweep_id = wandb.sweep(sweep = sweep_config, entity=\"abhinavtk\", project='MA23M002-A2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A-X4i5ygOGU4"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "  with wandb.init() as run:\n",
        "    run_name = \"-bs_\"+str(wandb.config.batch_size) +\"-ep_\"+str(wandb.config.epochs)+\"-lr_\"+str(wandb.config.lr) \\\n",
        "                  +\"-freeze_\"+str(wandb.config.freeze_percent)\n",
        "    wandb.run.name = run_name\n",
        "    pre_model = models.resnet50(pretrained=True)\n",
        "    cnn_model = pretrainedCNN(trainset, valset, pre_model, batch_size=wandb.config.batch_size, freeze_percent = wandb.config.freeze_percent)\n",
        "    cnn_model.train(wandb.config.epochs, wandb.config.lr, wandb.config.l2_reg)\n",
        "   wandb.agent(sweep_id, function = main, count = 10)\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSpH54oTwkDJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erv6q7pWwkGN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}