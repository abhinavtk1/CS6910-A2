{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U83iQvy_aVB6"
      },
      "outputs": [],
      "source": [
        "#Reference https://rumn.medium.com/part-1-ultimate-guide-to-fine-tuning-in-pytorch-pre-trained-model-and-its-configuration-8990194b71e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rNXPcfdaUqs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Gf7ft4yMQtj"
      },
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI61QxVPmnAO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7vqOzAIPQIc",
        "outputId": "db539932-534b-44de-b000-1c55429fab7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/CS6910-A2/CS6910-A2/train'\n",
        "test_dir = '/content/drive/MyDrive/CS6910-A2/CS6910-A2/val'\n",
        "\n",
        "#train_dir = '/kaggle/input/inaturalist/inaturalist_12K/train'\n",
        "#test_dir = '/kaggle/input/inaturalist/inaturalist_12K/val'\n",
        "IMG_SIZE = (224,224)\n",
        "\n",
        "# Transformations to apply to the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),  # Resize the images\n",
        "    transforms.ToTensor(),        # Convert images to PyTorch tensors\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ])  # Normalize the images\n",
        "\n",
        "\n",
        "# Use ImageFolder to create a dataset\n",
        "trainset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "val_size = int(0.2 * len(trainset))\n",
        "train_size = len(trainset) - val_size\n",
        "trainset, valset = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzJfMRBCcB45"
      },
      "outputs": [],
      "source": [
        "class pretrainedCNN():\n",
        "  def __init__(self, trainset, valset, model, batch_size=32, freeze_percent = 1):\n",
        "    # freeze earlier layers\n",
        "    self.model = model\n",
        "    if freeze_percent==1:\n",
        "      for param in self.model.parameters():\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "      total_layers = sum(1 for _ in model.parameters())\n",
        "      num_layers_to_freeze = int(freeze_percent * total_layers)\n",
        "\n",
        "      # Counter to track the number of frozen layers\n",
        "      frozen_layers = 0\n",
        "\n",
        "      # Freeze layers until reaching the desired percentage\n",
        "      for param in self.model.parameters():\n",
        "          param.requires_grad = False\n",
        "          frozen_layers += 1\n",
        "          if frozen_layers >= num_layers_to_freeze:\n",
        "              break\n",
        "\n",
        "    # Modify fully connected layer for fine-tuning\n",
        "    num_classes = 10  # Number of classes in iNaturalist dataset\n",
        "    num_ftrs = self.model.fc.in_features\n",
        "    model.fc = torch.nn.Linear(num_ftrs, num_classes)\n",
        "    for param in self.model.fc.parameters():\n",
        "      param.requires_grad = True\n",
        "    # DataLoader for the dataset\n",
        "    self.dataloader_train = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle=True)\n",
        "    self.dataloader_val = torch.utils.data.DataLoader(valset, batch_size = batch_size, shuffle=True)\n",
        "\n",
        "  def train(self, epochs = 10, lr=0.001, weight_decay=0):\n",
        "    self.model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    for epoch in range(1,epochs+1):\n",
        "      train_accuracy = 0\n",
        "      count = 0\n",
        "      self.model.train()\n",
        "      for inputs, labels in self.dataloader_train:\n",
        "          # forward, backward, and then weight update\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "          # Forward pass\n",
        "          optimizer.zero_grad()\n",
        "          y_pred = self.model(inputs)\n",
        "          loss = criterion(y_pred, labels)\n",
        "          train_accuracy += (torch.argmax(y_pred, 1) == labels).float().sum()\n",
        "          count += len(labels)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      train_accuracy /= count\n",
        "      print(\"Epoch %d: model train accuracy %.2f%%\" % (epoch, train_accuracy*100))\n",
        "      wandb.log({ 'epoch': epoch, 'train_accuracy': train_accuracy * 100})\n",
        "      self.model.eval()\n",
        "      with torch.no_grad():\n",
        "        val_accuracy = 0\n",
        "        count = 0\n",
        "        for inputs, labels in self.dataloader_val:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            y_pred = self.model(inputs)\n",
        "            val_loss = criterion(y_pred, labels)\n",
        "            val_accuracy += (torch.argmax(y_pred, 1) == labels).float().sum()\n",
        "            count += len(labels)\n",
        "        val_accuracy /= count\n",
        "        print(\"Epoch %d: model validation accuracy %.2f%%\" % (epoch, val_accuracy*100))\n",
        "        wandb.log({ 'epoch': epoch, 'validation_accuracy': val_accuracy * 100})\n",
        "        wandb.log({ 'epoch': epoch, 'validation_loss': val_loss * 100})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_model = models.resnet50(pretrained=True)\n",
        "cnn_model = pretrainedCNN(trainset, valset, pre_model, batch_size=64, freeze_percent = 0.9)\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.Adam(self.model.parameters(), lr=0.001, weight_decay=0)\n",
        "cnn_model.train(10, 0.0001, 0.005)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ-Hd1uWMV46",
        "outputId": "92212bf0-620b-40bc-b1f3-bbc7b6c4add7"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 181MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
        "dataloader_test = torch.utils.data.DataLoader(testset, batch_size = 64, shuffle=True)\n",
        "test_accuracy = 0\n",
        "count = 0\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(model.parameters(), lr=wandb.config.learning_rate, momentum=0.9)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0005)\n",
        "for inputs, labels in dataloader_test:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    print(type(inputs))\n",
        "    print(inputs.shape)\n",
        "    y_pred = cnn_model(inputs)\n",
        "    test_loss = loss_fn(y_pred, labels)\n",
        "    test_accuracy += (torch.argmax(y_pred, 1) == labels).float().sum()\n",
        "    count += len(labels)\n",
        "test_accuracy /= count\n",
        "print(\"Test accuracy %.2f%%\" % (test_accuracy*100))"
      ],
      "metadata": {
        "id": "-ARR8j9UNo9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erv6q7pWwkGN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}